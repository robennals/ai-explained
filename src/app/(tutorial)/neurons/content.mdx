# Neural Networks

<Lead>
What's the simplest building block that can learn to compute anything? Your brain
uses one. GPT and Claude use an artificial version of the same idea. You might
expect it to be fearsomely complex. It isn't. It's remarkably simple.
</Lead>

A neural network is made of **neurons**, connected together in layers. Each connection has a **weight** — a number that controls how much attention one neuron pays to another.

<NetworkOverviewWidget />

So how big are these networks? Here's a comparison of biological brains and AI systems, measured by their number of connections:

<NeuronScaleComparisonWidget />

But notice something strange in this chart. GPT-5 has roughly as many connections as a mouse brain (though comparing artificial parameters to biological synapses is not an exact match). Yet it can write essays and translate languages, and mice generally can't. And elephants and sperm whales have far more connections than humans, yet aren't smarter than us. The number of connections isn't everything — what matters most is **how good the weights are**. That's what training is all about, and we'll get deeper into it in later chapters.

## The Building Block

Each neuron receives inputs from the previous layer, does a little computation, and passes a result to the next layer. But what's happening inside each one? Let's zoom in.

A neuron does two things:

1. **Weighted sum.** Each input gets multiplied by a **weight** — a number that controls how much that input matters. All the weighted inputs get added together, plus a constant called the **bias**. This is just multiplication and addition: nothing fancy yet.
2. **Activation function.** The result gets passed through a function that determines how much to pass on to the next layer. This is called the **activation function**, and it's what makes neurons more than just arithmetic. We'll see exactly why it matters later in this chapter.

That's the whole thing. A neuron is a weighted sum followed by an activation function.

<NeuronDiagramWidget />

We said neural networks are remarkably simple, and they are. The structure of a neuron is just multiplication, addition, and passing the result through a function. Wire millions of them together and you have GPT — or the human brain. The hard part isn't building the network — it's finding the right values for all those weights and biases. That's what training is for, and we'll get deeper into it in later chapters. For now, let's understand what a single neuron can do.

One common activation function is the **sigmoid** — an S-shaped curve that smoothly squashes any number into the range 0 to 1. Large positive inputs become close to 1. Large negative inputs become close to 0. Everything in between gets a smooth, graded value. It's a "soft switch": instead of snapping between off and on, it dims smoothly between them. We'll use sigmoid throughout this chapter, and meet other activation functions later.

<SigmoidExplorerWidget />

Nature abhors a vacuum — but it loves an S-curve. An enormous number of real-world phenomena follow this shape: population growth, technology adoption, learning curves, the spread of diseases. And if a trend *doesn't* look S-shaped to you, it's probably because you're only seeing part of one. If it looks **exponential**, you're seeing the beginning of an S-curve. If it looks **linear**, you're seeing the middle. If it looks like **diminishing returns**, you're seeing the end.

<SigmoidZoomWidget />

The key property for neural networks: when you change a weight by a small amount, the output changes by a small amount. No sudden jumps, no unpredictable flips. That's exactly what Chapter 2 told us we need for optimization to work.

## Neurons as Logic

You may be familiar with basic logical operations like **AND**, **OR**, and **NOT**. These combine true-or-false values:

- **AND**: "Are *both* things true?" You need an umbrella if it's raining AND you're going outside.
- **OR**: "Is *at least one* thing true?" You'll get wet if it's raining OR someone sprays you with a hose.
- **NOT**: Flips the answer. NOT true is false, NOT false is true.

These simple operations are the basis for every digital computer. Inside every computer chip is a network of **logic gates** — tiny components that compute AND, OR, NOT, and similar operations on electrical signals. Wire enough of them together and you can compute anything: that's how your phone, your laptop, and every digital device works.

But logic gates have a problem. Their outputs snap between 0 and 1 with nothing in between. There's no smooth gradient to follow, which means you can't train a network of logic gates using the optimization techniques from Chapter 2.

There's one more operation worth knowing: **XOR** (short for "exclusive or"). It means "one or the other, but not both." Imagine a bunk bed — you have to sleep in the top bunk or the bottom bunk, but you can't sleep in both at the same time, and you can't sleep in neither (you have to pick one!). That's XOR. It turns out to be the trickiest of the bunch, as we're about to see.

A neuron is like a **smooth version of a logic gate**. With the right weights, a single two-input neuron can compute AND, OR, NOT, and more — but unlike a logic gate, its output changes smoothly when you adjust the weights. Let's see this in action:

<NeuronPlaygroundWidget />

<TryIt>
Start by sliding the input values and watching how the output changes. Then try the gate challenges: click AND to see the target outputs. Can you find weight and bias settings that match? If you get stuck, hit Optimize and watch gradient descent find the right weights automatically. Then try XOR — even optimization can't solve it with one neuron.
</TryIt>

But there's something important here beyond just mimicking logic gates. Notice what happens when you slide an input to a value *between* 0 and 1 — say 0.6. The output isn't forced to snap to "true" or "false." It can be somewhere in between: 0.73, or 0.4, or any other value. The neuron handles *degrees* naturally.

This matters because real-world data is rarely cleanly true or false. Is this email spam? Probably. Is that shadow in the photo a cat? Maybe. Is this patient sick? The test says 0.7 likely. A neuron can take uncertain inputs and produce a graded output — "probably true" rather than just "true" or "false."

When you clicked Optimize, the neuron found the right weights automatically. How? It uses the same idea from Chapter 2: define a **loss** that measures how wrong the outputs are, then follow the gradient downhill. Because the neuron is smooth — small weight changes produce small output changes — the loss landscape has slopes you can follow. That's gradient descent: calculate how each weight affects the error, nudge every weight a little in the right direction, repeat. The activation function is what keeps everything smooth and trainable.

<KeyInsight>
**A neuron is like a smooth, trainable logic gate.** With the right weights, it can compute AND, OR, NOT, and more — and because small changes to the weights produce small changes in the output, gradient descent can find those weights automatically. Neurons also handle in-between values naturally, making them building blocks for computation over uncertain, continuous data.
</KeyInsight>

## Neurons as Geometry

Instead of truth tables, think about *space*. A neuron takes two inputs — call them A and B. Every possible combination of A and B is a point in a 2D square. The neuron's output assigns a color to each point: green for high, red for low. What does that map look like?

<NeuronGeometryWidget />

<TryIt>
Click anywhere on the colored map (called a heatmap) to probe that point. Try the challenges and watch the colored regions shift. Hit Optimize on AND or OR and watch the boundary snap into place. Then try XOR — no matter what the optimizer does, the boundary stays a straight line, and it can't separate the diagonal corners.
</TryIt>

The key insight is geometric: a single neuron draws a **straight line** through input space. Everything on one side is green (high), everything on the other side is red (low). By adjusting the weights and bias, you can tilt and shift this line — but you can't bend it. AND, OR, and NOT are all separable by a single line. XOR is not: the "true" corners (0,1) and (1,0) sit on opposite diagonals, and no single line can separate them from the "false" corners.

<Callout type="info" title="The XOR Crisis">
In 1969, Minsky and Papert published *Perceptrons*, proving that single-layer networks can't solve XOR. This was taken as proof that neural networks were a dead end, and it killed most neural network research for over a decade — the "AI winter." The fix was always sitting there, obvious in hindsight: use more than one layer.
</Callout>

What if we add a second layer? Two hidden neurons each draw their own line. The output neuron combines them. Two lines can carve out a region that one line never could.

<TwoLayerPlaygroundWidget />

<TryIt>
Select XOR and click Optimize — watch two straight boundaries combine to separate the diagonal corners. Try the other solvable challenges (Vertical Band, Horizontal Band, Wedge) to see different two-line combinations. Then try Checkerboard or Center Only — even the optimizer can't solve these with just two hidden neurons.
</TryIt>

<Callout type="info" title="When Training Gets Stuck">
Sometimes the optimizer fails on a problem it should be able to solve. This happens when the random starting weights land in a flat region of the loss landscape — the gradients are too small for the optimizer to find its way out. The fix is simple: randomize the weights and try again. A different starting point often works on the first retry. We'll explore why this happens and how real systems handle it in later chapters.
</Callout>

Each hidden neuron contributes one decision boundary. The output neuron combines them — AND-ing, OR-ing, or blending them together. With just two hidden neurons you can solve XOR. 

<KeyInsight>
**One neuron = one straight line through input space.** It can separate points that fall on opposite sides of a line (AND, OR) but not patterns that require curves (XOR). Adding layers lets neurons combine their lines into more complex boundaries. Two neurons can solve XOR — how far can we go?
</KeyInsight>

## Sharp vs. Blurry

We've been talking about the *position* of a neuron's decision boundary — where the line falls in input space. But there's another property that matters: how **sharp** the transition is.

A neuron's boundary isn't a hard edge — it's a smooth gradient from low to high, thanks to the sigmoid. But you can make it sharper or blurrier without moving it. The trick: multiply all the weights and the bias by the same factor. This scales the input to the sigmoid up or down, which steepens or flattens the S-curve, while keeping the boundary in exactly the same place.

<SharpnessExplorerWidget />

<TryIt>
Drag the sharpness slider and watch both views. At low sharpness, the sigmoid is a gentle slope and the 2D map is a smooth blend. Crank it up and the curve snaps toward a step function — the boundary becomes a hard edge. Notice the weights and bias scale together.
</TryIt>

At the extreme, a very sharp neuron acts like a logic gate — snapping between 0 and 1 with almost nothing in between. This might sound desirable, but it's actually a problem for training. Remember: gradient descent needs smooth slopes to follow. When the sigmoid is nearly flat on both sides of a sharp step, the gradient almost vanishes — the optimizer can't tell which direction to move. This is why real networks use techniques called **regularization** (basically, rules that say "don't let any weight get too big") to keep neurons in the smooth, trainable middle ground.

## Training Deep Networks

We've seen that one neuron draws a single line, and two neurons can combine their lines to solve XOR. What happens when we keep going? Each neuron you add contributes another boundary. Each layer lets the network combine boundaries from the previous layer into more complex shapes. With enough neurons and layers, a neural network can carve up input space into **any** pattern — it can learn any function you can imagine. This is called the **universal approximation theorem**, and it's why neural networks are so powerful.

But can we actually *train* a big network? Here's why the answer is yes. Every weight in the network contributes to the final output, which means every weight contributes to the error. And if it contributes to the error, it has a gradient — a direction we can nudge it to make the error smaller.

The algorithm that computes all these gradients at once is called **backpropagation**. It flows the error signal backward from the output through every layer, so that every weight gets updated simultaneously. A network with ten thousand weights is no harder to train *in principle* than one with ten — it just takes more computation.

Let's see this in action. The widget below lets you build networks of different sizes and train them on various patterns. The challenge: what's the smallest network that can solve each one?

<NetworkTrainerWidget />

<TryIt>
Load a preset pattern and hit Train. Can you find the **smallest** network that solves each one? Try XOR with 1 layer — it fails. Switch to 2 layers and it works. The Circle needs more neurons per layer. Spirals need multiple layers and many neurons. You can also draw your own patterns: click to place green dots, shift-click or right-click for red, then train to see if the network can learn your pattern. Use "Reset Network" to re-randomize weights without losing your dots, or "Show Optimal" to see the smallest network that works.
</TryIt>

<KeyInsight>
**Backpropagation makes deep networks trainable.** The training signal flows backward from the output through every layer, telling each weight which way to adjust. Combined with the smoothness of neurons, this means you can optimize networks with millions of weights — which is how modern AI works.
</KeyInsight>

## What's Next

We've seen the full picture: neurons are smooth computation units, and because they're smooth, you can optimize them. Stack them in layers and you can compute anything. Backpropagation lets you train all the weights at once, even in deep networks. This is the core of how modern AI works — the architecture is simple, and training finds the right weights.

But so far we've been working with boolean logic and points in 2D space. Real AI systems like GPT don't work with true/false values — they work with *words*. How do you turn a word into something a neural network can process? In the next chapter, we'll see how words and concepts can be represented as lists of numbers — *embeddings* — where the numbers encode meaning itself as geometry.

<TryItInPyTorch notebook="neurons">
Build a neuron from scratch, implement AND/OR gates, watch a single neuron fail on XOR, then train a two-layer network that succeeds — and visualize its decision boundary.
</TryItInPyTorch>
