# Neural Networks

<Lead>
What's the simplest building block that can learn to compute anything? Your brain
uses one. GPT and Claude use an artificial version of the same idea. You might
expect it to be fearsomely complex. It isn't. It's remarkably simple.
</Lead>

A neural network is made of **neurons**, connected together in layers. Each connection has a **weight** — a number that controls how much attention one neuron pays to another.

<NetworkOverviewWidget />

So how big are these networks? Here's a comparison of biological brains and AI systems, measured by their number of connections:

<NeuronScaleComparisonWidget />

But notice something strange in this chart. GPT-5 has roughly as many connections as a mouse brain (though comparing artificial parameters to biological synapses is not an exact match). Yet it can write essays and translate languages, and mice generally can't. And elephants and sperm whales have far more connections than humans, yet aren't smarter than us. The number of connections isn't everything — what matters most is **how good the weights are**. That's what training is all about, and we'll get deeper into it in later chapters.

## The Building Block

Every neuron receives numbers as inputs and produces a number as output. Each neuron receives inputs from the previous layer, does a little computation, and passes a result to the next layer. But what's happening inside each one? Let's zoom in.

A neuron does two things:

1. **Weighted sum.** Each input gets multiplied by a **weight** — a number that controls how much that input matters. All the weighted inputs get added together, plus a constant called the **bias**. This is just multiplication and addition: nothing fancy yet.
2. **Activation function.** The result gets passed through a function that determines how much to pass on to the next layer. This is called the **activation function**, and it's what makes neurons more than just arithmetic. We'll see exactly why it matters later in this chapter.

That's the whole thing. A neuron is a weighted sum followed by an activation function.

<NeuronDiagramWidget />

The structure of a neuron is just multiplication, addition, and passing the result through a function. Wire millions of them together and you have GPT — or the human brain. The hard part isn't building the network — it's finding the right values for all those weights and biases. That's what training is for, and we'll get deeper into it in later chapters.

## Your First Neuron

Before we go further, let's get our hands on one. The widget below is a single neuron with two inputs. Every slider is yours to play with — there's no right answer here, just exploration.

<NeuronFreePlayWidget>
Try these experiments: What happens when both weights are positive and both inputs are high? What if you make one weight strongly negative? What does the bias do when the inputs are both zero? See if you can make the output stick near 0, near 1, and somewhere in between.
</NeuronFreePlayWidget>

## The Sigmoid

The activation function we're using is called the **sigmoid** — an S-shaped curve that smoothly squashes any number into the range 0 to 1. Large positive inputs become close to 1. Large negative inputs become close to 0. Everything in between gets a smooth, graded value. Think of it as a **dimmer switch**: instead of snapping between off and on like a light switch, it slides smoothly between them.

<SigmoidExplorerWidget>
Drag the input slider left and right. Notice how the output stays glued near 0 or 1 for extreme values, but changes rapidly in the middle. Where does the steepest part of the curve fall?
</SigmoidExplorerWidget>

Nature loves S-curves. An enormous number of real-world phenomena follow this shape: population growth, technology adoption, learning curves, the spread of diseases. And if a trend *doesn't* look S-shaped to you, it's probably because you're only seeing part of one. If it looks **exponential**, you're seeing the beginning of an S-curve. If it looks **linear**, you're seeing the middle. If it looks like **diminishing returns**, you're seeing the end.

<SigmoidZoomWidget />

The key property for neural networks: when you change a weight by a small amount, the output changes by a small amount. No sudden jumps, no unpredictable flips. That's exactly what Chapter 2 told us we need for optimization to work.

But you can make the sigmoid *sharper* or *smoother* by scaling the weights. Multiply all the weights and bias by a large number and the S-curve steepens toward a hard step. Scale them down and it flattens into a gentle slope. The boundary stays in the same place — only the sharpness changes.

<SharpnessExplorerWidget>
Drag the sharpness slider all the way up. The curve snaps almost like a light switch — 0 or 1, nothing in between. Now drag it down. The curve becomes a gentle slope.
</SharpnessExplorerWidget>

There's a catch, though. Very sharp neurons are harder to train. Remember from Chapter 2: optimization works by measuring how a small change in a weight affects the output. On the flat parts of a sharp sigmoid, the output barely changes at all — the slope is nearly zero. The optimizer gets stuck because it can't tell which direction to move. This is why real networks use techniques called **regularization** — rules that gently discourage any weight from getting too large — to keep neurons smooth and trainable. We'll cover regularization in a later chapter.

## Logic Gates

You may be familiar with basic logical operations like **AND**, **OR**, and **NOT**. These combine true-or-false values:

- **AND**: "Are *both* things true?" You need an umbrella if it's raining AND you're going outside.
- **OR**: "Is *at least one* thing true?" You'll get wet if it's raining OR someone sprays you with a hose.
- **NOT**: Flips the answer. NOT true is false, NOT false is true.

These simple operations are the basis for every digital computer. Inside every chip is a network of **logic gates** — tiny components that compute AND, OR, NOT, and similar operations on electrical signals. Wire enough of them together and you can compute anything.

<LogicGatePlaygroundWidget>
Click the inputs to toggle them between 0 and 1. Switch between AND, OR, and NOT with the tabs. Click the truth table rows to jump to that input combination.
</LogicGatePlaygroundWidget>

Wire enough gates together and you can build circuits that do real computation — like the one below, which uses just 10 gates to add two small numbers.

<GateCircuitDiagramWidget />

This is a tiny circuit, but the principle scales. Real computer chips assemble **billions** of gates on a single chip — enough to compute anything. Your phone, your laptop, every digital device works this way.

But logic gates have a problem. Their outputs snap between 0 and 1 with nothing in between. There's no smooth gradient to follow, which means you can't train a network of logic gates using the optimization techniques from Chapter 2. You can't ask "how should I adjust this gate to make the answer a *little* more correct?" — it's all or nothing.

## Neurons as Smooth Logic

One way to think of a neuron is as a **smooth version of a logic gate**. With the right weights, a single two-input neuron can compute AND, OR, NOT, and more — but unlike a logic gate, its output changes smoothly when you adjust the weights. That smooth change is what makes neurons trainable.

<NeuronPlaygroundWidget>
Click each gate tab to see the target outputs. Can you find weight and bias settings that match? If you get stuck, hit Optimize and watch the weights glide smoothly to a solution. Then try XOR — even the optimizer can't solve it with one neuron.
</NeuronPlaygroundWidget>

But there's something important here beyond just mimicking logic gates. Notice what happens when you slide an input to a value *between* 0 and 1 — say 0.6. The output isn't forced to snap to "true" or "false." It can be somewhere in between: 0.73, or 0.4, or any other value. The neuron handles *degrees* naturally — "probably true" rather than just "true" or "false."

This matters because real-world data is rarely cleanly true or false. Is this email spam? Probably. Is that shadow in the photo a cat? Maybe. A neuron can take uncertain inputs and produce a graded output.

<KeyInsight>
**One way to think of a neuron is as a smooth, trainable logic gate.** With the right weights, it can compute AND, OR, NOT, and more — and because small changes to the weights produce small changes in the output, we can find those weights using optimization. Neurons also handle in-between values naturally, making them building blocks for computation over uncertain, continuous data.
</KeyInsight>

## Two Neurons Solve XOR

There's one more operation worth knowing: **XOR** (short for "exclusive or"). It means "one or the other, but not both." You saw that a single neuron can't solve it — no matter what weights you try, it can't get all four input combinations right at once.

But what if we use *two* neurons feeding into a third?

Here's the trick:
- **Neuron 1** computes OR: "is *at least one* input on?"
- **Neuron 2** computes NAND (not-and): "are they *not both* on?"
- **Output neuron** computes AND of those two results: "at least one is on, AND they're not both on."

That's XOR. Three neurons, two layers — problem solved.

<TwoNeuronXORWidget>
Click each neuron to see its weights. Click the input nodes to toggle them between 0 and 1 and trace the signal through. Then hit Optimize and watch all three neurons find the right weights together.
</TwoNeuronXORWidget>

<Callout type="info" title="The XOR Crisis">
In 1969, Minsky and Papert published *Perceptrons*, proving that single-layer networks can't solve XOR. This was taken as proof that neural networks were a dead end, and it killed most neural network research for over a decade — the "AI winter." The fix was always sitting there, obvious in hindsight: use more than one layer.
</Callout>

## Deeper Networks

If two neurons can solve XOR, what happens when we keep adding more? Each neuron you add contributes another piece of the computation. Each layer lets the network combine results from the previous layer into something more complex.

The widget below lets you build networks of different sizes and explore them by hand. Try adjusting the architecture and clicking neurons to poke at their weights.

<DeepNetworkPlaygroundWidget>
Build a network with 4 inputs, 3 hidden layers of 5 neurons each, and 1 output. Click around and try sliding the weights. Can you make the output go to 1? To 0? Now imagine trying to set all those weights by hand to do something useful — like recognizing a digit or translating a sentence. That's hundreds of weights, and they all interact with each other.
</DeepNetworkPlaygroundWidget>

The point is: this would be *impossible* to do by hand for anything interesting. That's why we need to find values by training on real data, which we'll learn about in later chapters.

But here's why it works in principle. Every weight in the network contributes to the final output. If it contributes to the output, we can measure how changing it affects the error. And if we can measure that, we can use the optimization from Chapter 2 on **every weight at once**. The algorithm that does this is called **backpropagation** — it flows the error signal backward through every layer so each weight gets a nudge in the right direction.

How big do real networks get? GPT-3 has 96 layers. GPT-4 likely has even more. Even AI models that run on your smartphone have 20+ layers. The architecture is simple — the same building block repeated millions of times. The magic is in finding the right weights.

<KeyInsight>
**Stacking neurons in layers lets you compute anything.** Each layer combines the previous layer's outputs into something more complex. Backpropagation lets you train all the weights at once by flowing the error signal backward through every layer. A network with ten thousand weights is no harder to train *in principle* than one with ten — it just takes more computation.
</KeyInsight>

## What's Next

We've built up from a single neuron to deep networks. A neuron is just a weighted sum and an activation function — remarkably simple. But wire enough of them together, and finding the right weights is what creates the intelligence. Backpropagation makes that possible, even for networks with billions of weights.

But so far we've been working with small numbers — 0s and 1s, a handful of inputs. Real AI systems like GPT don't work with true/false values — they work with *words*. How do you turn a word into something a neural network can process? In the next chapter, we'll see how words and concepts can be represented as lists of numbers — *embeddings* — where the numbers encode meaning itself.

<TryItInPyTorch notebook="neurons">
Build a neuron from scratch, implement AND/OR gates, watch a single neuron fail on XOR, then train a two-layer network that succeeds — and visualize its decision boundary.
</TryItInPyTorch>
