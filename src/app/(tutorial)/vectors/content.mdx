# Vectors

<Lead>
The word "vector" sounds intimidating. It isn't. A vector is just a list of numbers.
But this simple idea turns out to be the key to understanding what neurons actually do — and why stacking them in layers works at all.
</Lead>

## A List of Numbers

You already use vectors every day. Your location on the planet is two numbers: (latitude, longitude). A color is three numbers: (red, green, blue). A velocity is two numbers: (east/west speed, north/south speed). Your character in a role-playing game might have stats like (health, strength, speed). Each of these is a vector — a list of numbers where each slot means something specific.

<VectorExamplesWidget>
Toggle between examples. Notice how each vector has a different number of slots (dimensions), and each slot measures something different. Change the sliders and watch the visual update — the numbers *are* the thing they describe. The velocity example is interesting: its two numbers naturally define a direction and a speed.
</VectorExamplesWidget>

The key idea: a vector is a compact way to describe something as a list of measurements. The number of measurements is the vector's **dimension** — a location is 2-dimensional, a color is 3-dimensional.

## Describing Animals with Vectors

Let's try describing animals as vectors. We'll score each animal on six properties: big, scary, hairy, cuddly, fast, and fat. Each score is a number between 0 and 1.

<AnimalPropertyExplorerWidget>
Click two different animals to compare their vectors side by side. Bear and dog are both hairy, but very different on scary. Cat and rabbit are close on cuddly but far apart on size. Which pair of animals has the most similar vectors?
</AnimalPropertyExplorerWidget>

Notice something important: the vector captures what we *chose* to measure. If we'd picked different properties — "can it fly?", "does it live in water?" — the same animals would get different vectors, and different animals would seem similar. **The choice of dimensions determines what the vector can distinguish.**

## Visualizing Vectors

Our animal vectors have six dimensions: big, scary, hairy, cuddly, fast, and fat. Six-dimensional spaces are hard to picture, but we're used to visualizing vectors in lower dimensions — so let's build up from one dimension and see how each new one helps.

With just **one** number, each animal is a point on a line.

<Vector1DExplorerWidget>
Switch between properties. On "Big," elephant and bear are far apart from mouse and rabbit — but cat and eagle end up right next to each other despite being nothing alike. One dimension captures one thing but conflates everything else.
</Vector1DExplorerWidget>

With **two** numbers, each animal is a point on a plane.

<Vector2DExplorerWidget>
Start with Big x Scary. Bear is big AND scary — upper right. Rabbit is small AND not scary — lower left. Try switching axes — every combination reveals different clusters. Notice how animals that were stuck together in 1D get pulled apart in 2D.
</Vector2DExplorerWidget>

With **three** numbers, each animal is a point in 3D space.

<Vector3DExplorerWidget>
Drag to rotate the view. Try Big x Scary x Cuddly — bear and shark overlap on big and scary, but adding cuddly pulls them apart because bear is cuddly and shark definitely isn't. Each new dimension lets you distinguish things that were previously mixed together.
</Vector3DExplorerWidget>

Three dimensions is the most we can directly visualize, but higher-dimensional vectors — like our six-dimensional animal vectors — are really just more of the same. Each new dimension is another axis, another way to pull apart things that looked the same in fewer dimensions. We just don't have an easy way to visualize them other than as lists of numbers. But the geometric intuition still holds: **nearby points are similar, far-apart points are different, and more dimensions mean finer distinctions.**

## Direction and Magnitude

So far we've represented vectors as lists of numbers, but there's another useful way to think about them: as **direction** plus **magnitude**.

- **Direction** = *what kind of thing is this?*
- **Magnitude** = *how much of this thing?*

Think about velocity: a car heading north-east at 60 mph. The direction tells you *where* it's going. The magnitude tells you *how fast*. Or think about colored light: the direction tells you the hue (red, blue, purple), and the magnitude tells you how bright it is.

In 2D we could use an angle for direction, but that breaks down in higher dimensions. Instead we use a **unit vector** — a vector that points in the same direction but has length 1. Any vector equals its unit vector (the direction) times its length (the magnitude).

<AnimalDirectionMagnitudeWidget>
Pick an example and drag the slider to change the magnitude. The dashed arrow is the unit vector — it sits on the arc where all unit-length vectors live. The solid arrow shows the full vector scaled by the amount. Try switching between Velocity and Color to see how "direction = what kind, magnitude = how much" applies everywhere.
</AnimalDirectionMagnitudeWidget>

This decomposition — direction times magnitude — will matter a lot in a moment, when we look at what the dot product really means.

## The Dot Product

The **dot product** is the single most important vector operation in AI. It takes two vectors and produces a single number. The recipe: multiply their lengths, then multiply by how similar their directions are.

**a · b = length(a) × length(b) × cosine(angle between them)**

The **cosine** measures direction similarity: 1 for identical directions, 0 for perpendicular, -1 for opposite. So if two vectors point the same way, the dot product is just their lengths multiplied together. If they're completely unrelated (perpendicular), it's zero — no matter how big they are. If they point in opposite directions, it's negative.

Often we work with vectors that are constrained to have length 1 — **unit vectors**. When both vectors are unit vectors, the lengths are just 1, so the dot product becomes pure directional similarity — just the cosine. This is called **cosine similarity**, and we'll see it again when we get to embeddings. 

<DotProductAnalogiesWidget>
Try the Animals tab: how similar is a bear to a shark? Both are unit vectors, so this is pure cosine similarity. Now try Velocity: how fast is a car going northward? Then Color: how much red gets through a red filter? The same operation answers different questions depending on what you feed it.
</DotProductAnalogiesWidget>

Remarkably, there's a completely different way to compute the dot product that gives the exact same result: **multiply each pair of corresponding numbers and add up the results.**

**a · b = (a₁×b₁) + (a₂×b₂) + … + (aₙ×bₙ)**

This always gives the same answer as the geometric formula. The geometry gives you the intuition; the computation is just multiply-and-add.

<DotProductExplorerWidget>
Drag the arrow tips. In Component view, watch the individual products and their sum. Switch to Projection view to see the angle and the projection of one vector onto the other. Both views always show the same number.
</DotProductExplorerWidget>

<KeyInsight>
**The dot product measures alignment.** Same direction → large positive. Perpendicular → zero. Opposite → large negative. This single operation is the foundation of how neural networks process information.
</KeyInsight>

## A Neuron Is (Mostly) a Dot Product

Here's the connection that ties everything together. Remember from the previous chapter that a neuron computes a **weighted sum** of its inputs, adds a bias, then applies an activation function. That weighted sum is a dot product — the neuron has a **weight vector** and receives an **input vector**:

<Callout>
**output = activation( w · x + bias )**

where **w** = (w₁, w₂, …, wₙ) is the weight vector and **x** = (x₁, x₂, …, xₙ) is the input vector.
</Callout>

The neuron is asking **"how much does this input point in the direction of what I'm looking for?"**. 

* **The direction** of the weight vector determines what the neuron is looking for. 
* **The magnitude** of the weight vector determines how much the neuron needs to see in order to get excited. 
* **The bias** determines how excited it is it hasn't seen anything at all.  

This is all a bit brain bending, but makes more sense if you play with it.

<NeuronDotProductWidget>
Drag the weight and input vectors. Watch the angle between them — when the vectors align (small angle), the output is high. When they're perpendicular (90°), the output depends mostly on the bias. When they oppose each other (large angle), the output drops. Try making the bias very negative — now the vectors need to be *very* well aligned for the neuron to fire. This visualization shows two dimensions, but real neurons have weight and input vectors with hundreds or thousands of dimensions — the same geometric intuition applies.
</NeuronDotProductWidget>

<KeyInsight>
**A neuron is a direction detector.** It computes the dot product of its input vector with its weight vector, adds a bias to shift the threshold, and squashes the result through an activation function. The weights define a direction in input space, and the neuron fires when the input points that way.
</KeyInsight>

## A Neuron Draws a Line

If a neuron fires when its input aligns with its weights, what does that look like geometrically?

Plot every possible input as a point in 2D space. The neuron's weighted sum — w₁ × x₁ + w₂ × x₂ + bias — defines a straight line through this space. On one side of the line, the output is close to 1. On the other side, close to 0. The line itself is the **decision boundary** — where the neuron is exactly 50/50.

<DecisionBoundaryExplorerWidget>
Click AND to see how the weight vector and bias draw a line that isolates the (1,1) corner. Click OR to see the line shift. Drag the weight vector or adjust the bias to see how they move the boundary. The blue input vector shows the output at any position — notice it always matches the heatmap. Now try XOR: no matter how you move the line, you can't get all four corners right.
</DecisionBoundaryExplorerWidget>

This is called **linear separability**: a problem is linearly separable if you can solve it with a single straight line (or, in higher dimensions, a flat surface). AND and OR are linearly separable. XOR is not — the "true" corners sit on opposite diagonals, and no single straight line can separate them from the "false" corners.

## Two Lines Solve XOR

If one neuron draws one line, what happens with *two* neurons? Two lines. And two lines can carve out regions that one line never could.

Each hidden neuron transforms the input into its own coordinate. In this new space, points that were on opposite corners get moved to the same side — what was inseparable becomes separable.

<XORBreakthroughWidget>
Switch from 1 layer to 2 layers. Watch the right panel — it shows what the hidden layer "sees." The four input points have been *moved*: in this new space, the two XOR-true cases are on one side and the two XOR-false cases are on the other. The hidden layer transformed an impossible problem into an easy one.
</XORBreakthroughWidget>

This is the fundamental insight about depth: **each layer transforms the data into a new representation where the next layer's job is easier.** The hidden layer doesn't solve the problem directly — it reshapes it into a problem that a single line *can* solve.

<KeyInsight>
**Depth transforms problems.** A single neuron draws one line. A hidden layer transforms the entire input space — stretching, folding, rearranging — so that what was inseparable becomes separable. Each layer makes the next layer's job easier.
</KeyInsight>

## Why Activation Functions Matter

If adding layers is so powerful, why not just stack a hundred? There's a catch — and it's the most important idea in this chapter.

Without the activation function, a neuron is just: output = w₁ × x₁ + w₂ × x₂ + bias. That's a **linear** function — just multiplication and addition. And here's the thing: **a linear function of a linear function is still a linear function.**

Layer 1 multiplies and adds. Layer 2 multiplies and adds again. But the whole thing simplifies to one multiplication and one addition. You could collapse a hundred layers into a single layer with different numbers. No matter how deep you go, you're still drawing one straight line.

It's like multiplying a number by 3, then by 5, then by 2. You could have just multiplied by 30.

The activation function *breaks* this. Because it bends the curve — it's not a straight line — two layers with activation are genuinely more powerful than one. This nonlinearity is what makes depth meaningful.

<LinearCollapseDemoWidget>
Turn off the activation function and set depth to 5 layers. Hit Train. No matter how long it runs, the boundary stays a straight line — five layers of nothing is still nothing. Now turn activation back on, keep 5 layers, hit Train. Watch the boundary bend and curve around the data. The activation function is the entire reason depth works.
</LinearCollapseDemoWidget>

<KeyInsight>
**Without activation functions, depth is an illusion.** A stack of linear layers always collapses to a single linear layer — the decision boundary is a straight line no matter how deep you go. The nonlinear activation is what makes each layer genuinely add to the network's expressive power.
</KeyInsight>

## What's Next

A vector is just a list of numbers — but it's a remarkably powerful idea. We've seen that a neuron computes the dot product of its input vector with its weight vector, which means it's a direction detector that draws a straight line through input space. Stacking neurons with activation functions lets networks curve those lines into any shape.

But so far we've been describing things with *hand-picked* properties — big, scary, hairy. That works for animals, because animals are one kind of thing and we can choose sensible properties for them. But what about words? "Dog" and "democracy" and "purple" and "running" — there's no single set of properties that makes sense for all of them. "How scary is the color blue?" isn't a meaningful question.

In the next chapter, we'll see how AI solves this problem: instead of choosing dimensions by hand, it *learns* vectors where similar words end up nearby and directions encode meaningful relationships — all without any human labeling.

<TryItInPyTorch notebook="vectors">
Create vectors in PyTorch, compute dot products and cosine similarity, build a neuron as a dot product, plot decision boundaries for AND/OR/XOR, and see why activation functions make depth meaningful.
</TryItInPyTorch>
