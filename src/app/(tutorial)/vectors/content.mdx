# Vectors

<Lead>
The word "vector" sounds intimidating. It isn't. A vector is just a list of numbers.
But this simple idea turns out to be the key to understanding what neurons actually do — and why stacking them in layers works at all.
</Lead>

## A List of Numbers

You already use vectors every day. Your location on the planet is two numbers: (latitude, longitude). A color is three numbers: (red, green, blue). A velocity is two numbers: (east/west speed, north/south speed). Your character in a role-playing game might have stats like (health, strength, speed). Each of these is a vector — a list of numbers where each slot means something specific.

<VectorExamplesWidget>
Toggle between examples. Notice how each vector has a different number of slots (dimensions), and each slot measures something different. Change the sliders and watch the visual update — the numbers *are* the thing they describe. The velocity example is interesting: its two numbers naturally define a direction and a speed.
</VectorExamplesWidget>

The key idea: a vector is a compact way to describe something as a list of measurements. The number of measurements is the vector's **dimension** — a location is 2-dimensional, a color is 3-dimensional.

## Describing Animals with Vectors

Let's try describing animals as vectors. We'll score each animal on six properties: big, scary, hairy, cuddly, fast, and fat. Each score is a number between 0 and 1.

<AnimalPropertyExplorerWidget>
Click two different animals to compare their vectors side by side. Bear and dog are both hairy, but very different on scary. Cat and rabbit are close on cuddly but far apart on size. Which pair of animals has the most similar vectors?
</AnimalPropertyExplorerWidget>

Notice something important: the vector captures what we *chose* to measure. If we'd picked different properties — "can it fly?", "does it live in water?" — the same animals would get different vectors, and different animals would seem similar. **The choice of dimensions determines what the vector can distinguish.**

## Visualizing Vectors

Our animal vectors have six dimensions: big, scary, hairy, cuddly, fast, and fat. Six-dimensional spaces are hard to picture, but we're used to visualizing vectors in lower dimensions — so let's build up from one dimension and see how each new one helps.

With just **one** number, each animal is a point on a line.

<Vector1DExplorerWidget>
Switch between properties. On "Big," elephant and bear are far apart from mouse and rabbit — but cat and eagle end up right next to each other despite being nothing alike. One dimension captures one thing but conflates everything else.
</Vector1DExplorerWidget>

With **two** numbers, each animal is a point on a plane.

<Vector2DExplorerWidget>
Start with Big x Scary. Bear is big AND scary — upper right. Rabbit is small AND not scary — lower left. Try switching axes — every combination reveals different clusters. Notice how animals that were stuck together in 1D get pulled apart in 2D.
</Vector2DExplorerWidget>

With **three** numbers, each animal is a point in 3D space.

<Vector3DExplorerWidget>
Drag to rotate the view. Try Big x Scary x Cuddly — bear and shark overlap on big and scary, but adding cuddly pulls them apart because bear is cuddly and shark definitely isn't. Each new dimension lets you distinguish things that were previously mixed together.
</Vector3DExplorerWidget>

Three dimensions is the most we can directly visualize, but higher-dimensional vectors — like our six-dimensional animal vectors — are really just more of the same. Each new dimension is another axis, another way to pull apart things that looked the same in fewer dimensions. We just don't have an easy way to visualize them other than as lists of numbers. But the geometric intuition still holds: **nearby points are similar, far-apart points are different, and more dimensions mean finer distinctions.**

## Direction and Magnitude

So far we've represented vectors as lists of numbers, but there's another useful way to think about them: as **direction** plus **magnitude**.

- **Direction** = *what kind of thing is this?*
- **Magnitude** = *how much of this thing?*

Back to animals: if you're worried about bears, you care about both "is this a bear?" (direction) and "how many are there?" (magnitude). One bear is worrying; a hundred bears is terrifying. The *kind* of danger is the same — it's the *amount* that changes.

In 2D we could use an angle for direction, but that breaks down in higher dimensions. Instead we use a **unit vector** — a vector that points in the same direction but has length 1. Any vector equals its unit vector (the direction) times its length (the magnitude).

<AnimalDirectionMagnitudeWidget>
Pick an item and drag the slider to change the magnitude. The dashed arrow is the unit vector — it sits on the arc where all unit-length vectors live. The faded arrow shows the full vector scaled by the count. Try switching between Animals, Velocity, and Color to see how "direction = what kind, magnitude = how much" applies everywhere.
</AnimalDirectionMagnitudeWidget>

<Callout>
Two dimensions aren't really enough to distinguish these animals well — bear and shark end up pointing in similar directions. With all six properties the differences are much clearer, but we can't easily draw a six-dimensional plot. This is a recurring tradeoff: more dimensions capture reality better, but we're stuck visualizing two or three at a time.
</Callout>

This decomposition — direction times magnitude — will matter a lot in a moment, when we look at what the dot product really means.

## The Dot Product

The **dot product** is the single most important vector operation in AI. It takes two vectors and produces a single number. The recipe: multiply their lengths, then multiply by how similar their directions are.

**a · b = length(a) × length(b) × cosine(angle between them)**

The **cosine** measures direction similarity: 1 for identical directions, 0 for perpendicular, -1 for opposite. So if two vectors point the same way, the dot product is just their lengths multiplied together. If they're completely unrelated (perpendicular), it's zero — no matter how big they are. If they point in opposite directions, it's negative.

<DotProductAnalogiesWidget>
Pick a detector and something to measure. The green arrow shows the projection — the component of the input that goes in the detector's direction. Try the Animals tab: how much "bear" is in "3 bears"? Now Velocity: how fast is this car going northward? Then Color: how much red gets through a red filter? Notice how the same operation answers different questions depending on what you feed it.
</DotProductAnalogiesWidget>

There's a completely different way to compute the exact same number: **multiply each pair of corresponding numbers and add up the results.**

**a · b = (a₁×b₁) + (a₂×b₂) + … + (aₙ×bₙ)**

This always gives the same answer as the geometric formula. The geometry gives you the intuition; the computation is just multiply-and-add.

<DotProductExplorerWidget>
Drag the arrow tips. In Component view, watch the individual products and their sum. Switch to Projection view to see the angle and the projection of one vector onto the other. Both views always show the same number.
</DotProductExplorerWidget>

When both vectors are unit vectors (length 1), the lengths are just 1, so the dot product becomes pure directional similarity — just the cosine. This is called **cosine similarity**, and we'll see it again when we get to embeddings.

<KeyInsight>
**The dot product measures alignment.** Same direction → large positive. Perpendicular → zero. Opposite → large negative. This single operation is the foundation of how neural networks process information.
</KeyInsight>

## A Neuron Is (Mostly) a Dot Product

Here's the connection that ties everything together. Remember from the previous chapter that a neuron computes a **weighted sum** of its inputs, adds a bias, then applies the sigmoid. That weighted sum is a dot product — the neuron has a **weight vector** and receives an **input vector**:

<Callout>
**output = sigmoid( w · x + bias )**

where **w** = (w₁, w₂, …, wₙ) is the weight vector and **x** = (x₁, x₂, …, xₙ) is the input vector.
</Callout>

The weight vector's direction says *what kind of input* the neuron is looking for. Its magnitude says *how interested* it is — bigger weights mean a stronger response. The input vector's direction says *what kind of thing* arrived, and its magnitude says *how much*. The dot product combines all of this: when a large input matches what the neuron cares strongly about, the result is big, the sigmoid outputs close to 1, and the neuron fires. When the input is unrelated (perpendicular), the dot product is near zero. When it's the opposite of what the neuron wants, it stays quiet.

<NeuronDotProductWidget>
Drag the weight and input vectors. Watch the angle between them — when the vectors align (small angle), the output is high. When they're perpendicular (90°), the output depends mostly on the bias. When they oppose each other (large angle), the output drops. Try making the bias very negative — now the vectors need to be *very* well aligned for the neuron to fire. This visualization shows two dimensions, but real neurons have weight and input vectors with hundreds or thousands of dimensions — the same geometric intuition applies.
</NeuronDotProductWidget>

<KeyInsight>
**A neuron is a direction detector.** It computes the dot product of its input vector with its weight vector, adds a bias to shift the threshold, and squashes the result through the sigmoid. The weights define a direction in input space, and the neuron fires when the input points that way.
</KeyInsight>

## A Neuron Draws a Line

If a neuron fires when its input aligns with its weights, what does that look like geometrically?

Plot every possible input as a point in 2D space. The neuron's weighted sum — w₁ × x₁ + w₂ × x₂ + bias — defines a straight line through this space. On one side of the line, the output is close to 1. On the other side, close to 0. The line itself is the **decision boundary** — where the neuron is exactly 50/50.

<DecisionBoundaryExplorerWidget>
Drag the line to solve AND — isolate the (1,1) corner. Then solve OR — isolate (0,0) on the other side. Both are easy. Now try XOR: put (0,1) and (1,0) together while keeping (0,0) and (1,1) apart. No matter how you rotate or shift the line, you can't get all four right. XOR is not a straight-line problem.
</DecisionBoundaryExplorerWidget>

This is called **linear separability**: a problem is linearly separable if you can solve it with a single straight line (or, in higher dimensions, a flat surface). AND and OR are linearly separable. XOR is not — the "true" corners sit on opposite diagonals, and no single straight line can separate them from the "false" corners.

## Two Lines Solve XOR

If one neuron draws one line, what happens with *two* neurons? Two lines. And two lines can carve out regions that one line never could.

Each hidden neuron transforms the input into its own coordinate. In this new space, points that were on opposite corners get moved to the same side — what was inseparable becomes separable.

<XORBreakthroughWidget>
Switch from 1 layer to 2 layers. Watch the right panel — it shows what the hidden layer "sees." The four input points have been *moved*: in this new space, the two XOR-true cases are on one side and the two XOR-false cases are on the other. The hidden layer transformed an impossible problem into an easy one.
</XORBreakthroughWidget>

This is the fundamental insight about depth: **each layer transforms the data into a new representation where the next layer's job is easier.** The hidden layer doesn't solve the problem directly — it reshapes it into a problem that a single line *can* solve.

<KeyInsight>
**Depth transforms problems.** A single neuron draws one line. A hidden layer transforms the entire input space — stretching, folding, rearranging — so that what was inseparable becomes separable. Each layer makes the next layer's job easier.
</KeyInsight>

## Why Activation Functions Matter

If adding layers is so powerful, why not just stack a hundred? There's a catch — and it's the most important idea in this chapter.

Without the activation function, a neuron is just: output = w₁ × x₁ + w₂ × x₂ + bias. That's a **linear** function — just multiplication and addition. And here's the thing: **a linear function of a linear function is still a linear function.**

Layer 1 multiplies and adds. Layer 2 multiplies and adds again. But the whole thing simplifies to one multiplication and one addition. You could collapse a hundred layers into a single layer with different numbers. No matter how deep you go, you're still drawing one straight line.

It's like multiplying a number by 3, then by 5, then by 2. You could have just multiplied by 30.

The activation function *breaks* this. Because it bends the curve — it's not a straight line — two layers with activation are genuinely more powerful than one. This nonlinearity is what makes depth meaningful.

<LinearCollapseDemoWidget>
Turn off the activation function and set depth to 5 layers. Hit Train. No matter how long it runs, the boundary stays a straight line — five layers of nothing is still nothing. Now turn activation back on, keep 5 layers, hit Train. Watch the boundary bend and curve around the data. The activation function is the entire reason depth works.
</LinearCollapseDemoWidget>

<KeyInsight>
**Without activation functions, depth is an illusion.** A stack of linear layers always collapses to a single linear layer — the decision boundary is a straight line no matter how deep you go. The nonlinear activation is what makes each layer genuinely add to the network's expressive power.
</KeyInsight>

## What's Next

A vector is just a list of numbers — but it's a remarkably powerful idea. We've seen that a neuron computes the dot product of its input vector with its weight vector, which means it's a direction detector that draws a straight line through input space. Stacking neurons with activation functions lets networks curve those lines into any shape.

But so far we've been describing things with *hand-picked* properties — big, scary, hairy. That works for animals, because animals are one kind of thing and we can choose sensible properties for them. But what about words? "Dog" and "democracy" and "purple" and "running" — there's no single set of properties that makes sense for all of them. "How scary is the color blue?" isn't a meaningful question.

In the next chapter, we'll see how AI solves this problem: instead of choosing dimensions by hand, it *learns* vectors where similar words end up nearby and directions encode meaningful relationships — all without any human labeling.

<TryItInPyTorch notebook="vectors">
Create vectors in PyTorch, compute dot products and cosine similarity, build a neuron as a dot product, plot decision boundaries for AND/OR/XOR, and see why activation functions make depth meaningful.
</TryItInPyTorch>
