# Vectors

<Lead>
The word "vector" sounds intimidating. It isn't. A vector is just a list of numbers.
But this simple idea turns out to be the key to understanding what neurons actually do — and why stacking them in layers works at all.
</Lead>

## A List of Numbers

You already use vectors every day. Your location on the planet is two numbers: (latitude, longitude). A color is three numbers: (red, green, blue). A velocity is two numbers: (east/west speed, north/south speed). Your character in a role-playing game might have stats like (health, strength, speed). Each of these is a vector — a list of numbers where each slot means something specific.

<VectorExamplesWidget>
Toggle between examples. Notice how each vector has a different number of slots (dimensions), and each slot measures something different. Change the sliders and watch the visual update — the numbers *are* the thing they describe. The velocity example is interesting: its two numbers naturally define a direction and a speed.
</VectorExamplesWidget>

The key idea: a vector is a compact way to describe something as a list of measurements. The number of measurements is the vector's **dimension** — a location is 2-dimensional, a color is 3-dimensional.

## Describing Animals with Vectors

Let's try describing animals as vectors. We'll score each animal on six properties: big, scary, hairy, cuddly, fast, and fat. Each score is a number between 0 and 1.

<AnimalPropertyExplorerWidget>
Click two different animals to compare their vectors side by side. Bear and dog are both hairy, but very different on scary. Cat and rabbit are close on cuddly but far apart on size. Which pair of animals has the most similar vectors?
</AnimalPropertyExplorerWidget>

Notice something important: the vector captures what we *chose* to measure. If we'd picked different properties — "can it fly?", "does it live in water?" — the same animals would get different vectors, and different animals would seem similar. **The choice of dimensions determines what the vector can distinguish.**

## Visualizing Vectors

Our animal vectors have six dimensions: big, scary, hairy, cuddly, fast, and fat. Six-dimensional spaces are hard to picture, but we're used to visualizing vectors in lower dimensions — so let's build up from one dimension and see how each new one helps.

With just **one** number, each animal is a point on a line.

<Vector1DExplorerWidget>
Switch between properties. On "Big," elephant and bear are far apart from mouse and rabbit — but cat and eagle end up right next to each other despite being nothing alike. One dimension captures one thing but conflates everything else.
</Vector1DExplorerWidget>

With **two** numbers, each animal is a point on a plane.

<Vector2DExplorerWidget>
Start with Big x Scary. Bear is big AND scary — upper right. Rabbit is small AND not scary — lower left. Try switching axes — every combination reveals different clusters. Notice how animals that were stuck together in 1D get pulled apart in 2D.
</Vector2DExplorerWidget>

With **three** numbers, each animal is a point in 3D space.

<Vector3DExplorerWidget>
Drag to rotate the view. Try Big x Scary x Cuddly — bear and shark overlap on big and scary, but adding cuddly pulls them apart because bear is cuddly and shark definitely isn't. Each new dimension lets you distinguish things that were previously mixed together.
</Vector3DExplorerWidget>

Three dimensions is the most we can directly visualize, but higher-dimensional vectors — like our six-dimensional animal vectors — are really just more of the same. Each new dimension is another axis, another way to pull apart things that looked the same in fewer dimensions. We just don't have an easy way to visualize them other than as lists of numbers. But the geometric intuition still holds: **nearby points are similar, far-apart points are different, and more dimensions mean finer distinctions.**

## Direction and Magnitude

So far we've represented vectors as lists of numbers, but there's another useful way to think about them: as **direction** plus **magnitude**.

- **Direction** = *what kind of thing is this?*
- **Magnitude** = *how much of this thing?*

Think about velocity: a car heading north-east at 60 mph. The direction tells you *where* it's going. The magnitude tells you *how fast*. Or think about colored light: the direction tells you the hue (red, blue, purple), and the magnitude tells you how bright it is.

In 2D we could use an angle for direction, but that breaks down in higher dimensions. Instead we use a **unit vector** — a vector that points in the same direction but has length 1. Any vector equals its unit vector (the direction) times its length (the magnitude).

<AnimalDirectionMagnitudeWidget>
Pick an example and drag the slider to change the magnitude. The dashed arrow is the unit vector — it sits on the arc where all unit-length vectors live. The solid arrow shows the full vector scaled by the amount. Try switching between Velocity and Color to see how "direction = what kind, magnitude = how much" applies everywhere.
</AnimalDirectionMagnitudeWidget>


## Comparing Directions

We just saw that every vector has a direction (its unit vector) and a magnitude (its length). So how do we tell whether two vectors point in a similar direction?

Here's a simple trick: take the two unit vectors, **multiply each pair of matching numbers, and add up the results.** This gives you a similarity score:

- **1** means they point in exactly the same direction
- **0** means they're perpendicular (at right angles — nothing in common)
- **−1** means they point in exactly opposite directions

<DirectionSimilarityWidget>
On the Arrows tab, drag the two arrows around. When they point the same way, the similarity is near 1. When they're at right angles, it's near 0. When they point opposite ways, it's near −1. Then switch to the Animals tab to see how this works with our six-dimensional animal vectors — each property gets multiplied pair by pair and added up.
</DirectionSimilarityWidget>

Why does multiply-and-add measure similarity? Look at the Animals tab. If two animals both score high on a property, multiplying gives a big number — that shared trait contributes a lot. But if one animal is cuddly and the other isn't, multiplying gives almost nothing. Add up all these products, and you get a total similarity score: high when the animals are similar, low when they aren't.

In AI, this is called **cosine similarity** — you'll see the term a lot.

## The Dot Product

Comparing unit vectors gives us a direction similarity score. But what if the vectors aren't unit length? The **dot product** extends this idea: it's the direction similarity, scaled by both vectors' magnitudes.

**a · b = length(a) × length(b) × similarity(direction of a, direction of b)**

This is the single most important vector operation in AI. If two vectors point in the same direction *and* are both large, the dot product is large. If they point in opposite directions, it's a large negative number. If they're perpendicular, it's zero — no matter how big they are.

It turns out you can compute the dot product the same way as before — just multiply each pair of matching numbers and add up the results, without needing to separate out direction and magnitude first:

**a · b = (a₁×b₁) + (a₂×b₂) + … + (aₙ×bₙ)**

Both formulas give exactly the same answer. The first gives you the intuition; the second gives you the computation.

<DotProductExplorerWidget>
Drag the two vectors around. Watch how the dot product changes — it's large when both vectors are long and point the same way, and zero when they're perpendicular. The two computations on the right always give the same result.
</DotProductExplorerWidget>

To make it easy to visualize, we're showing this in two dimensions — but dot products work for vectors with any number of dimensions. In AI, vectors typically have hundreds or thousands of dimensions, and the same multiply-and-add formula applies to all of them.

<KeyInsight>
**The dot product measures alignment.** Same direction → large positive. Perpendicular → zero. Opposite → large negative. This single operation is the foundation of how neural networks process information.
</KeyInsight>

## A Neuron Is (Mostly) a Dot Product

Here's the connection that ties everything together. Remember from the previous chapter that a neuron computes a **weighted sum** of its inputs, adds a bias, then applies an activation function. That weighted sum is a dot product — the neuron has a **weight vector** and receives an **input vector**:

<Callout>
**output = activation( w · x + bias )**

where **w** = (w₁, w₂, …, wₙ) is the weight vector and **x** = (x₁, x₂, …, xₙ) is the input vector.
</Callout>

The neuron is asking **"how much does this input point in the direction of what I'm looking for?"**. 

* **The direction** of the weight vector determines what the neuron is looking for. 
* **The magnitude** of the weight vector determines how much of what it's looking for the neuron needs to see in order to get excited. 
* **The bias** determines how excited it is if it hasn't seen anything at all.  

This is all a bit brain bending, but makes more sense if you play with it.

<NeuronDotProductWidget>
Drag the weight and input vectors. Watch the angle between them — when the vectors align (small angle), the output is high. When they're perpendicular (90°), the output depends mostly on the bias. When they oppose each other (large angle), the output drops. Try making the bias very negative — now the vectors need to be *very* well aligned for the neuron to fire. This visualization shows two dimensions, but real neurons have weight and input vectors with hundreds or thousands of dimensions — the same geometric intuition applies.
</NeuronDotProductWidget>

<KeyInsight>
**A neuron is a direction detector.** It computes the dot product of its input vector with its weight vector, adds a bias to shift the threshold, and squashes the result through an activation function. The weights define a direction in input space, and the neuron fires when the input points that way.
</KeyInsight>

## A Neuron Draws a Line

If a neuron fires when its input aligns with its weights, what does that look like across *all possible inputs*?

The heatmap below shows the neuron's output for every point in 2D input space. Green means the neuron fires (output near 1), red means it doesn't (output near 0). The dashed white line is the **decision boundary** — where the output is exactly 0.5.

<NeuronDecisionBoundaryWidget>
Drag the weight vector (orange) to point in different directions — watch the decision boundary rotate to stay perpendicular to it. Drag the input vector (blue) around and watch its output match the heatmap. Now adjust the bias: positive bias pushes the boundary away from the weight vector (more green), negative bias pushes it toward the weight vector (more red). Notice that the weight vector's *direction* controls the angle of the line, while the bias controls where the line sits.
</NeuronDecisionBoundaryWidget>

The decision boundary is always a straight line, perpendicular to the weight vector. On the side the weight vector points toward, inputs align with the weights and the neuron fires. On the other side, inputs oppose the weights and the neuron stays quiet. The bias shifts this line toward or away from the origin — it controls *how much* alignment the neuron demands before it fires.

This is why a single neuron can only learn **linearly separable** patterns — patterns where you can draw a straight line (or in higher dimensions, a flat surface) between the "yes" cases and the "no" cases. That's a real limitation, but as we'll see in a later chapter, stacking neurons in layers lets the network draw much more complex boundaries.

## What's Next

A vector is just a list of numbers — but it's a remarkably powerful idea. We've seen that a neuron computes the dot product of its input vector with its weight vector, making it a direction detector: it fires when its input aligns with what it's looking for.

But so far we've been describing things with *hand-picked* properties — big, scary, hairy. That works for animals, because animals are one kind of thing and we can choose sensible properties for them. But what about words? "Dog" and "democracy" and "purple" and "running" — there's no single set of properties that makes sense for all of them. "How scary is the color blue?" isn't a meaningful question.

In the next chapter, we'll see how AI solves this problem: instead of choosing dimensions by hand, it *learns* vectors where similar words end up nearby and directions encode meaningful relationships — all without any human labeling.

<TryItInPyTorch notebook="vectors">
Create vectors in PyTorch, compute dot products and cosine similarity, and build a neuron as a dot product.
</TryItInPyTorch>
