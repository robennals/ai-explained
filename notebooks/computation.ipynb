{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Everything Is Numbers — Try it in PyTorch\n",
    "\n",
    "This is an **optional** hands-on companion to [Chapter 1](https://learnai.robennals.org/computation). Run each cell to see the concepts from the chapter come alive in real PyTorch code."
   ]
  },
  {
   "cell_type": "code",
   "id": "setup",
   "metadata": {},
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "m4ud5lsf2o",
   "source": "## What's a \"tensor\"?\n\nIn PyTorch, a **tensor** is just a collection of numbers — like a container that can hold numbers in different shapes:\n\n- A single number: `torch.tensor(42)` — just one value\n- A list of numbers: `torch.tensor([1, 2, 3])` — like a row in a spreadsheet\n- A grid of numbers: `torch.tensor([[1, 2], [3, 4]])` — like a small spreadsheet\n- A cube of numbers (or higher!) — like a stack of spreadsheets\n\nThe word sounds fancy, but it's really just \"numbers arranged in a box.\" A 1D tensor is a list, a 2D tensor is a table, a 3D tensor is a stack of tables, and so on. PyTorch uses tensors for everything because GPUs are really fast at doing math on big collections of numbers all at once.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "text-header",
   "metadata": {},
   "source": [
    "## Text as Numbers"
   ]
  },
  {
   "cell_type": "code",
   "id": "text-code",
   "metadata": {},
   "source": "# Every character has a number (Unicode code point)\ntext = \"Hello, AI!\"\nnumbers = [ord(c) for c in text]\nprint(f\"Text: {text}\")\nprint(f\"Numbers: {numbers}\")\n\n# PyTorch stores these as a tensor (just a list of numbers here)\ntext_tensor = torch.tensor(numbers)\nprint(f\"\\nAs a PyTorch tensor: {text_tensor}\")\nprint(f\"Tensor shape: {text_tensor.shape}\")  # shape tells you the size of each dimension\n\n# Convert back to text\ndecoded = ''.join(chr(n) for n in text_tensor.tolist())\nprint(f\"Decoded back: {decoded}\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "images-header",
   "metadata": {},
   "source": [
    "## Images as Numbers"
   ]
  },
  {
   "cell_type": "code",
   "id": "images-code",
   "metadata": {},
   "source": "# An image is a 3D tensor (a stack of grids): height × width × color channels (RGB)\n# Each pixel has 3 numbers: how much red, green, and blue (from 0.0 to 1.0)\nimage = torch.zeros(4, 4, 3)  # Start with all black (all zeros)\n\n# Paint some pixels\nimage[0, 0] = torch.tensor([1.0, 0.0, 0.0])  # Red\nimage[0, 3] = torch.tensor([0.0, 0.0, 1.0])  # Blue\nimage[1, 1] = torch.tensor([0.0, 1.0, 0.0])  # Green\nimage[2, 2] = torch.tensor([1.0, 1.0, 0.0])  # Yellow\nimage[3, 3] = torch.tensor([1.0, 1.0, 1.0])  # White\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 3))\nax1.imshow(image.numpy())\nax1.set_title(\"Our 4×4 image\")\nax1.set_xticks(range(4))\nax1.set_yticks(range(4))\n\n# Show the raw numbers for the red channel\nax2.imshow(image[:, :, 0].numpy(), cmap='Reds', vmin=0, vmax=1)\nax2.set_title(\"Red channel values\")\nax2.set_xticks(range(4))\nax2.set_yticks(range(4))\nfor i in range(4):\n    for j in range(4):\n        ax2.text(j, i, f\"{image[i,j,0]:.1f}\", ha='center', va='center', fontsize=10)\n\nplt.tight_layout()\nplt.show()\n\nprint(f\"Image tensor shape: {image.shape}  (height × width × RGB)\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "sound-header",
   "metadata": {},
   "source": [
    "## Sound as Numbers"
   ]
  },
  {
   "cell_type": "code",
   "id": "sound-code",
   "metadata": {},
   "source": "# Sound is a 1D tensor (just a list of numbers): amplitude values over time\n# Each number says how far the speaker cone pushes in or out at that instant\nsample_rate = 16000  # 16,000 samples per second\nduration = 0.01      # 10 milliseconds (so we can see the wave)\nfrequency = 440      # A4 note (440 Hz)\n\nt = torch.linspace(0, duration, int(sample_rate * duration))\nwaveform = torch.sin(2 * torch.pi * frequency * t)\n\nplt.figure(figsize=(8, 3))\nplt.plot(t.numpy() * 1000, waveform.numpy())\nplt.xlabel(\"Time (ms)\")\nplt.ylabel(\"Amplitude\")\nplt.title(f\"Sound wave at {frequency} Hz (A4 note) — just numbers!\")\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\nprint(f\"Waveform tensor shape: {waveform.shape}\")\nprint(f\"First 5 values: {waveform[:5]}\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "function-header",
   "metadata": {},
   "source": [
    "## Thinking Is a Function"
   ]
  },
  {
   "cell_type": "code",
   "id": "function-code",
   "metadata": {},
   "source": [
    "# A \"model\" is just a function with adjustable parameters (knobs)\n",
    "# Here's a simple polynomial: f(x) = a*x^2 + b*x + c\n",
    "\n",
    "x = torch.linspace(-3, 3, 100)\n",
    "\n",
    "params = [\n",
    "    (1.0, 0.0, 0.0, \"a=1, b=0, c=0\"),\n",
    "    (0.5, -1.0, 2.0, \"a=0.5, b=-1, c=2\"),\n",
    "    (-0.3, 2.0, -1.0, \"a=-0.3, b=2, c=-1\"),\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "for a, b, c, label in params:\n",
    "    y = a * x**2 + b * x + c\n",
    "    plt.plot(x.numpy(), y.numpy(), label=label, linewidth=2)\n",
    "\n",
    "plt.xlabel(\"Input (x)\")\n",
    "plt.ylabel(\"Output f(x)\")\n",
    "plt.title(\"Same function structure, different parameters \\u2192 different behavior\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "lookup-header",
   "metadata": {},
   "source": [
    "## The Lookup Table Explosion"
   ]
  },
  {
   "cell_type": "code",
   "id": "lookup-code",
   "metadata": {},
   "source": [
    "# How big would a lookup table need to be?\n",
    "\n",
    "# For a tiny 8x8 grayscale image (64 pixels, 256 values each)\n",
    "tiny_pixels = 64\n",
    "tiny_log10 = tiny_pixels * np.log10(256)\n",
    "print(f\"Lookup table for 8\\u00d78 grayscale image: 256^64 \\u2248 10^{tiny_log10:.0f} entries\")\n",
    "\n",
    "# For a real 256x256 RGB image\n",
    "real_image_pixels = 256 * 256 * 3\n",
    "real_log10 = real_image_pixels * np.log10(256)\n",
    "print(f\"\\n256\\u00d7256 RGB image has {real_image_pixels:,} values\")\n",
    "print(f\"Lookup table entries: 256^{real_image_pixels} \\u2248 10^{real_log10:.0f}\")\n",
    "\n",
    "print(f\"\\nAtoms in the observable universe: ~10^80\")\n",
    "print(f\"Lookup table for tiny 8\\u00d78 image needs: ~10^{tiny_log10:.0f} entries\")\n",
    "print(f\"\\nThat's 10^{tiny_log10 - 80:.0f} times MORE than atoms in the universe!\")\n",
    "print(f\"Lookup tables are impossibly large. We need something smarter.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "footer",
   "metadata": {},
   "source": "---\n\n*This notebook accompanies [Chapter 1: Everything Is Numbers](https://learnai.robennals.org/computation). The interactive widgets in the web version let you explore these concepts visually.*\n\n*New to PyTorch? See the [PyTorch from Scratch](https://learnai.robennals.org/appendix-pytorch) appendix for a beginner-friendly introduction.*"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}